{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1119761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/catpc/.cache/kagglehub/datasets/mlg-ulb/creditcardfraud/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb0e584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "csv_path = os.path.join(path, 'creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d437e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4e1136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23baa4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check imblance data\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b9d012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='Class'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Class'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6709dd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d899710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    19961\n",
       "1       39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=20000)\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec22ad42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "009cfc5b",
   "metadata": {},
   "source": [
    "# 1. Train model on imblance dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33729840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f77cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3992    0]\n",
      " [   2    6]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3992\n",
      "           1       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      0.88      0.93      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "Accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(x_train,y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = rf_model.score(x_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0434a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ed06b70",
   "metadata": {},
   "source": [
    "# 2. Apply Sampling Techniques(RandomeOverSampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46fe6c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#Initialize RAndomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "#perform Random Oversampling\n",
    "x_ros,y_ros = ros.fit_resample(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc1c70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    15969\n",
       "1    15969\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ros.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf0c21ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Random OverSampling): \n",
      "[[3992    0]\n",
      " [   2    6]]\n",
      "[[3992    0]\n",
      " [   2    6]]\n",
      "\n",
      "Classification Report (Random OverSampling): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3992\n",
      "           1       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      0.88      0.93      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "0.9995\n"
     ]
    }
   ],
   "source": [
    "#Initialize the model \n",
    "rf_model_ros = RandomForestClassifier()\n",
    "\n",
    "#train the model on RAndom Oversampled data\n",
    "rf_model_ros.fit(x_ros,y_ros)\n",
    "\n",
    "#predict on the test set\n",
    "y_pred_ros = rf_model_ros.predict(x_test)\n",
    "\n",
    "\n",
    "#calculate confusion matrix\n",
    "conf_matrix_ros = confusion_matrix(y_test, y_pred_ros)\n",
    "print(\"Confusion Matrix (Random OverSampling): \")\n",
    "print(conf_matrix_ros)\n",
    "print(conf_matrix_ros)\n",
    "\n",
    "\n",
    "\n",
    "#calculate classification report\n",
    "class_report_ros = classification_report(y_test,y_pred_ros)\n",
    "print(\"\\nClassification Report (Random OverSampling): \")\n",
    "print(class_report_ros)\n",
    "accuracy_ros = rf_model_ros.score(x_test,y_test)\n",
    "print(accuracy_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba14b5b",
   "metadata": {},
   "source": [
    "# 3.Random Undersampling : (RandomeUnderSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5fdb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    31\n",
       "1    31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#Initialize RAndomOverSampler\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "#perform Random Oversampling\n",
    "x_rus,y_rus = rus.fit_resample(x_train,y_train)\n",
    "\n",
    "\n",
    "y_rus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49160256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Random OverSampling): \n",
      "[[3951   41]\n",
      " [   1    7]]\n",
      "[[3951   41]\n",
      " [   1    7]]\n",
      "\n",
      "Classification Report (Random OverSampling): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3992\n",
      "           1       0.15      0.88      0.25         8\n",
      "\n",
      "    accuracy                           0.99      4000\n",
      "   macro avg       0.57      0.93      0.62      4000\n",
      "weighted avg       1.00      0.99      0.99      4000\n",
      "\n",
      "0.9895\n"
     ]
    }
   ],
   "source": [
    "#Initialize the model \n",
    "rf_model_rus = RandomForestClassifier()\n",
    "\n",
    "#train the model on RAndom Oversampled data\n",
    "rf_model_rus.fit(x_rus,y_rus)\n",
    "\n",
    "#predict on the test set\n",
    "y_pred_rus = rf_model_rus.predict(x_test)\n",
    "\n",
    "\n",
    "#calculate confusion matrix\n",
    "conf_matrix_rus = confusion_matrix(y_test, y_pred_rus)\n",
    "print(\"Confusion Matrix (Random OverSampling): \")\n",
    "print(conf_matrix_rus)\n",
    "print(conf_matrix_rus)\n",
    "\n",
    "\n",
    "\n",
    "#calculate classification report\n",
    "class_report_rus = classification_report(y_test,y_pred_rus)\n",
    "print(\"\\nClassification Report (Random OverSampling): \")\n",
    "print(class_report_rus)\n",
    "accuracy_rus = rf_model_rus.score(x_test,y_test)\n",
    "print(accuracy_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d500d5",
   "metadata": {},
   "source": [
    "# SMOTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca9cfd",
   "metadata": {},
   "source": [
    "# Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cb78803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    15969\n",
       "1    15969\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "#Initialize Smote\n",
    "smote = SMOTE()\n",
    "\n",
    "#perform Smote\n",
    "x_smote, y_smote = smote.fit_resample(x_train,y_train)\n",
    "y_smote.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f210ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Random OverSampling): \n",
      "[[3992    0]\n",
      " [   2    6]]\n",
      "[[3992    0]\n",
      " [   2    6]]\n",
      "\n",
      "Classification Report (Random OverSampling): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3992\n",
      "           1       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      0.88      0.93      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "0.9895\n"
     ]
    }
   ],
   "source": [
    "#Initialize the model \n",
    "rf_model_smote = RandomForestClassifier()\n",
    "\n",
    "#train the model on RAndom Oversampled data\n",
    "rf_model_smote.fit(x_smote,y_smote)\n",
    "\n",
    "#predict on the test set\n",
    "y_pred_smote = rf_model_smote.predict(x_test)\n",
    "\n",
    "\n",
    "#calculate confusion matrix\n",
    "conf_matrix_smote = confusion_matrix(y_test, y_pred_smote)\n",
    "print(\"Confusion Matrix (Random OverSampling): \")\n",
    "print(conf_matrix_smote)\n",
    "print(conf_matrix_smote)\n",
    "\n",
    "\n",
    "\n",
    "#calculate classification report\n",
    "class_report_smote = classification_report(y_test,y_pred_smote)\n",
    "print(\"\\nClassification Report (Random OverSampling): \")\n",
    "print(class_report_smote)\n",
    "accuracy_smote = rf_model_rus.score(x_test,y_test)\n",
    "print(accuracy_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c87df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ab79bde",
   "metadata": {},
   "source": [
    "# Precdiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5c6a72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Class :  0\n",
      "Predicted Class: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/catpc/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#get the input data as a 2d array \n",
    "\n",
    "inputs_1 = x_test.iloc[[10]].values\n",
    "\n",
    "#predict with the model\n",
    "prediction = rf_model_smote.predict(inputs_1)\n",
    "print(\"Actual Class : \", y_test.iloc[10])\n",
    "print(\"Predicted Class:\", prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20a38c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Class :  0\n",
      "Predicted Class: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/catpc/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#get the input data as a 2d array \n",
    "\n",
    "inputs_1 = x_test.iloc[[151]].values\n",
    "\n",
    "#predict with the model\n",
    "prediction = rf_model_smote.predict(inputs_1)\n",
    "print(\"Actual Class : \", y_test.iloc[151])\n",
    "print(\"Predicted Class:\", prediction[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
