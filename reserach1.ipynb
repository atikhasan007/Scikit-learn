{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9710583,
          "sourceType": "datasetVersion",
          "datasetId": 5939633
        }
      ],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebooka237e15054",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atikhasan007/Scikit-learn/blob/main/reserach1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "mdrifaturrahman33_levir_cd_path = kagglehub.dataset_download('mdrifaturrahman33/levir-cd')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "0Pk9bh2N_EW2"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:22:53.394448Z",
          "iopub.execute_input": "2025-10-17T19:22:53.39462Z",
          "iopub.status.idle": "2025-10-17T19:22:55.280943Z",
          "shell.execute_reply.started": "2025-10-17T19:22:53.394604Z",
          "shell.execute_reply": "2025-10-17T19:22:55.280169Z"
        },
        "id": "WY2rxPKi_EW4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, concatenate, Input, Lambda, Dropout, MaxPooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:22:59.492935Z",
          "iopub.execute_input": "2025-10-17T19:22:59.493236Z",
          "iopub.status.idle": "2025-10-17T19:23:14.000511Z",
          "shell.execute_reply.started": "2025-10-17T19:22:59.493214Z",
          "shell.execute_reply": "2025-10-17T19:23:13.999788Z"
        },
        "id": "otsoSi7o_EW5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet_model(input_size=(256, 256, 6)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Split the input into two separate RGB images\n",
        "    input_image1 = inputs[..., :3]\n",
        "    input_image2 = inputs[..., 3:]\n",
        "\n",
        "    # Encoder for image 1\n",
        "    c1_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_image1)\n",
        "    c1_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1_1)\n",
        "    c1_1 = Dropout(0.3)(c1_1)  # Dropout after convolutional blocks\n",
        "    p1_1 = MaxPooling2D((2, 2))(c1_1)\n",
        "\n",
        "    c2_1 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1_1)\n",
        "    c2_1 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2_1)\n",
        "    c2_1 = Dropout(0.3)(c2_1)  # Dropout after convolutional blocks\n",
        "    p2_1 = MaxPooling2D((2, 2))(c2_1)\n",
        "\n",
        "    c3_1 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2_1)\n",
        "    c3_1 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3_1)\n",
        "    c3_1 = Dropout(0.3)(c3_1)  # Dropout after convolutional blocks\n",
        "    p3_1 = MaxPooling2D((2, 2))(c3_1)\n",
        "\n",
        "    # Encoder for image 2 (same as image 1)\n",
        "    c1_2 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_image2)\n",
        "    c1_2 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1_2)\n",
        "    c1_2 = Dropout(0.3)(c1_2)  # Dropout after convolutional blocks\n",
        "    p1_2 = MaxPooling2D((2, 2))(c1_2)\n",
        "\n",
        "    c2_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1_2)\n",
        "    c2_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2_2)\n",
        "    c2_2 = Dropout(0.3)(c2_2)  # Dropout after convolutional blocks\n",
        "    p2_2 = MaxPooling2D((2, 2))(c2_2)\n",
        "\n",
        "    c3_2 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2_2)\n",
        "    c3_2 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3_2)\n",
        "    c3_2 = Dropout(0.3)(c3_2)  # Dropout after convolutional blocks\n",
        "    p3_2 = MaxPooling2D((2, 2))(c3_2)\n",
        "\n",
        "    # Bottleneck (concatenate the features from both images)\n",
        "    c4_1 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3_1)\n",
        "    c4_1 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4_1)\n",
        "    c4_1 = Dropout(0.4)(c4_1)  # Dropout after convolutional blocks\n",
        "\n",
        "    c4_2 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3_2)\n",
        "    c4_2 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4_2)\n",
        "    c4_2 = Dropout(0.4)(c4_2)  # Dropout after convolutional blocks\n",
        "\n",
        "    # Combine the features of both images at the bottleneck\n",
        "    c4 = concatenate([c4_1, c4_2])\n",
        "\n",
        "    # Decoder\n",
        "    u5 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c4)\n",
        "    u5 = concatenate([u5, c3_1, c3_2])  # Skip connection from both images encoders\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(u5)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c2_1, c2_2])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Dropout(0.3)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
        "    c6 = Dropout(0.3)(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c1_1, c1_2])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Dropout(0.3)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
        "    c7 = Dropout(0.3)(c7)\n",
        "\n",
        "    # Final output\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:28:16.190086Z",
          "iopub.execute_input": "2025-10-17T19:28:16.19083Z",
          "iopub.status.idle": "2025-10-17T19:28:16.204382Z",
          "shell.execute_reply.started": "2025-10-17T19:28:16.190805Z",
          "shell.execute_reply": "2025-10-17T19:28:16.203674Z"
        },
        "id": "qfwSNRY5_EW6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet_with_resnet(input_shape=(256, 256, 6)):\n",
        "    # Split the input into two separate images (image1 and image2)\n",
        "    inputs = Input(input_shape)\n",
        "    input_image1 = inputs[..., :3]  # First 3 channels\n",
        "    input_image2 = inputs[..., 3:]  # Last 3 channels\n",
        "\n",
        "    # Pretrained ResNet50 as the backbone\n",
        "    base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(256, 256, 3))\n",
        "\n",
        "    # Extract encoder layers\n",
        "    encoder_layers1 = [\n",
        "        base_model.get_layer(\"conv1_relu\").output,\n",
        "        base_model.get_layer(\"conv2_block3_out\").output,\n",
        "        base_model.get_layer(\"conv3_block4_out\").output,\n",
        "        base_model.get_layer(\"conv4_block6_out\").output,\n",
        "        base_model.get_layer(\"conv5_block3_out\").output\n",
        "    ]\n",
        "\n",
        "    # Create the encoder model for image1\n",
        "    encoder1 = Model(inputs=base_model.input, outputs=encoder_layers1)\n",
        "    encoder1.trainable = False  # Freeze pretrained layers initially\n",
        "\n",
        "    # Extract features for image1\n",
        "    encoder_outputs1 = encoder1(input_image1)\n",
        "\n",
        "    # Extract features for image2 using the same encoder\n",
        "    encoder_outputs2 = encoder1(input_image2)\n",
        "\n",
        "    # Combine encoder outputs\n",
        "    combined_features = [\n",
        "        Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]), name=f\"abs_diff_{i}\")([feat1, feat2])\n",
        "        for i, (feat1, feat2) in enumerate(zip(encoder_outputs1, encoder_outputs2))\n",
        "    ]\n",
        "\n",
        "    # Decoder with skip connections\n",
        "    c1, c2, c3, c4, c5 = combined_features\n",
        "\n",
        "    # Decoder 1\n",
        "    u6 = UpSampling2D((2, 2))(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Dropout(0.3)(c6)  # Add Dropout here\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "    c6 = Dropout(0.3)(c6)  # Add Dropout here\n",
        "\n",
        "    # Decoder 2\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Dropout(0.3)(c7)  # Add Dropout here\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "    c7 = Dropout(0.3)(c7)  # Add Dropout here\n",
        "\n",
        "    # Decoder 3\n",
        "    u8 = UpSampling2D((2, 2))(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = Dropout(0.3)(c8)  # Add Dropout here\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "    c8 = Dropout(0.3)(c8)  # Add Dropout here\n",
        "\n",
        "    # Decoder 4\n",
        "    u9 = UpSampling2D((2, 2))(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = Dropout(0.3)(c9)  # Add Dropout here\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "    c9 = Dropout(0.3)(c9)  # Add Dropout here\n",
        "\n",
        "    # Final output\n",
        "    u10 = UpSampling2D((2, 2))(c9)\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(u10)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:28:30.939423Z",
          "iopub.execute_input": "2025-10-17T19:28:30.939701Z",
          "iopub.status.idle": "2025-10-17T19:28:30.95069Z",
          "shell.execute_reply.started": "2025-10-17T19:28:30.939681Z",
          "shell.execute_reply": "2025-10-17T19:28:30.949865Z"
        },
        "id": "GmT8FKo6_EW7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# ===============================\n",
        "# Build SiHDNet-like UNet model\n",
        "def build_sihdnet_model(input_size=(256, 256, 6)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Split the input into two separate RGB images\n",
        "    input_image1 = inputs[..., :3]\n",
        "    input_image2 = inputs[..., 3:]\n",
        "\n",
        "    # ---------------- Encoder for image 1 ----------------\n",
        "    def encoder_block(x, filters):\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(x)\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(c)\n",
        "        c = Dropout(0.3)(c)\n",
        "        p = MaxPooling2D((2,2))(c)\n",
        "        return c, p\n",
        "\n",
        "    c1_1, p1_1 = encoder_block(input_image1, 64)\n",
        "    c2_1, p2_1 = encoder_block(p1_1, 128)\n",
        "    c3_1, p3_1 = encoder_block(p2_1, 256)\n",
        "\n",
        "    # ---------------- Encoder for image 2 ----------------\n",
        "    c1_2, p1_2 = encoder_block(input_image2, 64)\n",
        "    c2_2, p2_2 = encoder_block(p1_2, 128)\n",
        "    c3_2, p3_2 = encoder_block(p2_2, 256)\n",
        "\n",
        "    # ---------------- Bottleneck ----------------\n",
        "    c4_1 = Conv2D(512, (3,3), activation='relu', padding='same')(p3_1)\n",
        "    c4_1 = Conv2D(512, (3,3), activation='relu', padding='same')(c4_1)\n",
        "    c4_1 = Dropout(0.4)(c4_1)\n",
        "\n",
        "    c4_2 = Conv2D(512, (3,3), activation='relu', padding='same')(p3_2)\n",
        "    c4_2 = Conv2D(512, (3,3), activation='relu', padding='same')(c4_2)\n",
        "    c4_2 = Dropout(0.4)(c4_2)\n",
        "\n",
        "    # Combine features from both images\n",
        "    c4 = concatenate([c4_1, c4_2])\n",
        "\n",
        "    # ---------------- Decoder ----------------\n",
        "    def decoder_block(x, skip1, skip2, filters):\n",
        "        u = Conv2DTranspose(filters, (2,2), strides=(2,2), padding='same')(x)\n",
        "        u = concatenate([u, skip1, skip2])\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(u)\n",
        "        c = Dropout(0.3)(c)\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(c)\n",
        "        c = Dropout(0.3)(c)\n",
        "        return c\n",
        "\n",
        "    c5 = decoder_block(c4, c3_1, c3_2, 256)\n",
        "    c6 = decoder_block(c5, c2_1, c2_2, 128)\n",
        "    c7 = decoder_block(c6, c1_1, c1_2, 64)\n",
        "\n",
        "    # ---------------- Output ----------------\n",
        "    outputs = Conv2D(1, (1,1), activation='sigmoid')(c7)\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "# ===============================\n",
        "# Instantiate SiHDNet model\n",
        "model_sihdnet = build_sihdnet_model(input_size=(256, 256, 6))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:28:44.056916Z",
          "iopub.execute_input": "2025-10-17T19:28:44.05767Z",
          "iopub.status.idle": "2025-10-17T19:28:46.301276Z",
          "shell.execute_reply.started": "2025-10-17T19:28:44.057646Z",
          "shell.execute_reply": "2025-10-17T19:28:46.30058Z"
        },
        "id": "ZZAlU_9w_EW8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# ===============================\n",
        "# Build GLAI-Net-like UNet model\n",
        "def build_glainet_model(input_size=(256, 256, 6)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Split the input into two separate RGB images\n",
        "    input_image1 = inputs[..., :3]\n",
        "    input_image2 = inputs[..., 3:]\n",
        "\n",
        "    # ---------------- Encoder for image 1 ----------------\n",
        "    c1_1 = Conv2D(64, (3,3), activation='relu', padding='same')(input_image1)\n",
        "    c1_1 = Conv2D(64, (3,3), activation='relu', padding='same')(c1_1)\n",
        "    c1_1 = Dropout(0.3)(c1_1)\n",
        "    p1_1 = MaxPooling2D((2,2))(c1_1)\n",
        "\n",
        "    c2_1 = Conv2D(128, (3,3), activation='relu', padding='same')(p1_1)\n",
        "    c2_1 = Conv2D(128, (3,3), activation='relu', padding='same')(c2_1)\n",
        "    c2_1 = Dropout(0.3)(c2_1)\n",
        "    p2_1 = MaxPooling2D((2,2))(c2_1)\n",
        "\n",
        "    c3_1 = Conv2D(256, (3,3), activation='relu', padding='same')(p2_1)\n",
        "    c3_1 = Conv2D(256, (3,3), activation='relu', padding='same')(c3_1)\n",
        "    c3_1 = Dropout(0.3)(c3_1)\n",
        "    p3_1 = MaxPooling2D((2,2))(c3_1)\n",
        "\n",
        "    # ---------------- Encoder for image 2 ----------------\n",
        "    c1_2 = Conv2D(64, (3,3), activation='relu', padding='same')(input_image2)\n",
        "    c1_2 = Conv2D(64, (3,3), activation='relu', padding='same')(c1_2)\n",
        "    c1_2 = Dropout(0.3)(c1_2)\n",
        "    p1_2 = MaxPooling2D((2,2))(c1_2)\n",
        "\n",
        "    c2_2 = Conv2D(128, (3,3), activation='relu', padding='same')(p1_2)\n",
        "    c2_2 = Conv2D(128, (3,3), activation='relu', padding='same')(c2_2)\n",
        "    c2_2 = Dropout(0.3)(c2_2)\n",
        "    p2_2 = MaxPooling2D((2,2))(c2_2)\n",
        "\n",
        "    c3_2 = Conv2D(256, (3,3), activation='relu', padding='same')(p2_2)\n",
        "    c3_2 = Conv2D(256, (3,3), activation='relu', padding='same')(c3_2)\n",
        "    c3_2 = Dropout(0.3)(c3_2)\n",
        "    p3_2 = MaxPooling2D((2,2))(c3_2)\n",
        "\n",
        "    # ---------------- Bottleneck ----------------\n",
        "    c4_1 = Conv2D(512, (3,3), activation='relu', padding='same')(p3_1)\n",
        "    c4_1 = Conv2D(512, (3,3), activation='relu', padding='same')(c4_1)\n",
        "    c4_1 = Dropout(0.4)(c4_1)\n",
        "\n",
        "    c4_2 = Conv2D(512, (3,3), activation='relu', padding='same')(p3_2)\n",
        "    c4_2 = Conv2D(512, (3,3), activation='relu', padding='same')(c4_2)\n",
        "    c4_2 = Dropout(0.4)(c4_2)\n",
        "\n",
        "    c4 = concatenate([c4_1, c4_2])\n",
        "\n",
        "    # ---------------- Decoder ----------------\n",
        "    u5 = Conv2DTranspose(256, (2,2), strides=(2,2), padding='same')(c4)\n",
        "    u5 = concatenate([u5, c3_1, c3_2])\n",
        "    c5 = Conv2D(256, (3,3), activation='relu', padding='same')(u5)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3,3), activation='relu', padding='same')(c5)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c2_1, c2_2])\n",
        "    c6 = Conv2D(128, (3,3), activation='relu', padding='same')(u6)\n",
        "    c6 = Dropout(0.3)(c6)\n",
        "    c6 = Conv2D(128, (3,3), activation='relu', padding='same')(c6)\n",
        "    c6 = Dropout(0.3)(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c1_1, c1_2])\n",
        "    c7 = Conv2D(64, (3,3), activation='relu', padding='same')(u7)\n",
        "    c7 = Dropout(0.3)(c7)\n",
        "    c7 = Conv2D(64, (3,3), activation='relu', padding='same')(c7)\n",
        "    c7 = Dropout(0.3)(c7)\n",
        "\n",
        "    # ---------------- Output ----------------\n",
        "    outputs = Conv2D(1, (1,1), activation='sigmoid')(c7)\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:28:56.304645Z",
          "iopub.execute_input": "2025-10-17T19:28:56.305251Z",
          "iopub.status.idle": "2025-10-17T19:28:56.320328Z",
          "shell.execute_reply.started": "2025-10-17T19:28:56.305228Z",
          "shell.execute_reply": "2025-10-17T19:28:56.319575Z"
        },
        "id": "q1Q2hKIZ_EW9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Multiply, Add\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# ===============================\n",
        "# Build MTFSR-like UNet model with simple Dynamic Attention Unit\n",
        "def build_mtfsr_model(input_size=(256, 256, 6)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Split the input into two separate RGB images\n",
        "    input_image1 = inputs[..., :3]\n",
        "    input_image2 = inputs[..., 3:]\n",
        "\n",
        "    # ---------------- Encoder for image 1 ----------------\n",
        "    def encoder_block(x, filters):\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(x)\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(c)\n",
        "        c = Dropout(0.3)(c)\n",
        "        p = MaxPooling2D((2,2))(c)\n",
        "        return c, p\n",
        "\n",
        "    c1_1, p1_1 = encoder_block(input_image1, 64)\n",
        "    c2_1, p2_1 = encoder_block(p1_1, 128)\n",
        "    c3_1, p3_1 = encoder_block(p2_1, 256)\n",
        "\n",
        "    # ---------------- Encoder for image 2 ----------------\n",
        "    c1_2, p1_2 = encoder_block(input_image2, 64)\n",
        "    c2_2, p2_2 = encoder_block(p1_2, 128)\n",
        "    c3_2, p3_2 = encoder_block(p2_2, 256)\n",
        "\n",
        "    # ---------------- Bottleneck ----------------\n",
        "    c4_1 = Conv2D(512, (3,3), activation='relu', padding='same')(p3_1)\n",
        "    c4_1 = Conv2D(512, (3,3), activation='relu', padding='same')(c4_1)\n",
        "    c4_1 = Dropout(0.4)(c4_1)\n",
        "\n",
        "    c4_2 = Conv2D(512, (3,3), activation='relu', padding='same')(p3_2)\n",
        "    c4_2 = Conv2D(512, (3,3), activation='relu', padding='same')(c4_2)\n",
        "    c4_2 = Dropout(0.4)(c4_2)\n",
        "\n",
        "    # ---------------- Dynamic Attention Unit ----------------\n",
        "    attention = Multiply()([c4_1, c4_2])  # Simple feature interaction\n",
        "    c4 = Add()([c4_1, c4_2, attention])  # Combine with residual\n",
        "\n",
        "    # ---------------- Decoder ----------------\n",
        "    def decoder_block(x, skip1, skip2, filters):\n",
        "        u = Conv2DTranspose(filters, (2,2), strides=(2,2), padding='same')(x)\n",
        "        u = concatenate([u, skip1, skip2])\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(u)\n",
        "        c = Dropout(0.3)(c)\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(c)\n",
        "        c = Dropout(0.3)(c)\n",
        "        return c\n",
        "\n",
        "    c5 = decoder_block(c4, c3_1, c3_2, 256)\n",
        "    c6 = decoder_block(c5, c2_1, c2_2, 128)\n",
        "    c7 = decoder_block(c6, c1_1, c1_2, 64)\n",
        "\n",
        "    # ---------------- Output ----------------\n",
        "    outputs = Conv2D(1, (1,1), activation='sigmoid')(c7)\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:29:04.011045Z",
          "iopub.execute_input": "2025-10-17T19:29:04.011601Z",
          "iopub.status.idle": "2025-10-17T19:29:04.0217Z",
          "shell.execute_reply.started": "2025-10-17T19:29:04.011576Z",
          "shell.execute_reply": "2025-10-17T19:29:04.020799Z"
        },
        "id": "xu-IIetZ_EW-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# ===============================\n",
        "# Build SiHDNet-like UNet model\n",
        "def build_sifanet_model(input_size=(256, 256, 6)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Split the input into two separate RGB images\n",
        "    input_image1 = inputs[..., :3]\n",
        "    input_image2 = inputs[..., 3:]\n",
        "\n",
        "    # ---------------- Encoder for image 1 ----------------\n",
        "    def encoder_block(x, filters):\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(x)\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(c)\n",
        "        c = Dropout(0.3)(c)\n",
        "        p = MaxPooling2D((2,2))(c)\n",
        "        return c, p\n",
        "\n",
        "    c1_1, p1_1 = encoder_block(input_image1, 64)\n",
        "    c2_1, p2_1 = encoder_block(p1_1, 128)\n",
        "    c3_1, p3_1 = encoder_block(p2_1, 256)\n",
        "\n",
        "    # ---------------- Encoder for image 2 ----------------\n",
        "    c1_2, p1_2 = encoder_block(input_image2, 64)\n",
        "    c2_2, p2_2 = encoder_block(p1_2, 128)\n",
        "    c3_2, p3_2 = encoder_block(p2_2, 256)\n",
        "\n",
        "    # ---------------- Bottleneck ----------------\n",
        "    c4_1 = Conv2D(512, (3,3), activation='relu', padding='same')(p3_1)\n",
        "    c4_1 = Conv2D(512, (3,3), activation='relu', padding='same')(c4_1)\n",
        "    c4_1 = Dropout(0.4)(c4_1)\n",
        "\n",
        "    c4_2 = Conv2D(512, (3,3), activation='relu', padding='same')(p3_2)\n",
        "    c4_2 = Conv2D(512, (3,3), activation='relu', padding='same')(c4_2)\n",
        "    c4_2 = Dropout(0.4)(c4_2)\n",
        "\n",
        "    # Combine features from both images\n",
        "    c4 = concatenate([c4_1, c4_2])\n",
        "\n",
        "    # ---------------- Decoder ----------------\n",
        "    def decoder_block(x, skip1, skip2, filters):\n",
        "        u = Conv2DTranspose(filters, (2,2), strides=(2,2), padding='same')(x)\n",
        "        u = concatenate([u, skip1, skip2])\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(u)\n",
        "        c = Dropout(0.3)(c)\n",
        "        c = Conv2D(filters, (3,3), activation='relu', padding='same')(c)\n",
        "        c = Dropout(0.3)(c)\n",
        "        return c\n",
        "\n",
        "    c5 = decoder_block(c4, c3_1, c3_2, 256)\n",
        "    c6 = decoder_block(c5, c2_1, c2_2, 128)\n",
        "    c7 = decoder_block(c6, c1_1, c1_2, 64)\n",
        "\n",
        "    # ---------------- Output ----------------\n",
        "    outputs = Conv2D(1, (1,1), activation='sigmoid')(c7)\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:32:47.020721Z",
          "iopub.execute_input": "2025-10-17T19:32:47.021284Z",
          "iopub.status.idle": "2025-10-17T19:32:47.031998Z",
          "shell.execute_reply.started": "2025-10-17T19:32:47.02126Z",
          "shell.execute_reply": "2025-10-17T19:32:47.030902Z"
        },
        "id": "XZfxwoRl_EW_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (256, 256, 6)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:30:27.94085Z",
          "iopub.execute_input": "2025-10-17T19:30:27.941184Z",
          "iopub.status.idle": "2025-10-17T19:30:27.945095Z",
          "shell.execute_reply.started": "2025-10-17T19:30:27.941161Z",
          "shell.execute_reply": "2025-10-17T19:30:27.944066Z"
        },
        "id": "D4w4E5ai_EXA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_unet = build_unet_model(input_shape)\n",
        "model_unet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_unet.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:30:36.683702Z",
          "iopub.execute_input": "2025-10-17T19:30:36.68455Z",
          "iopub.status.idle": "2025-10-17T19:30:36.952941Z",
          "shell.execute_reply.started": "2025-10-17T19:30:36.684521Z",
          "shell.execute_reply": "2025-10-17T19:30:36.952251Z"
        },
        "id": "qq4hUSa__EXA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_unet_with_resnet = build_unet_with_resnet(input_shape)\n",
        "model_unet_with_resnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_unet_with_resnet.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:31:03.44869Z",
          "iopub.execute_input": "2025-10-17T19:31:03.449245Z",
          "iopub.status.idle": "2025-10-17T19:31:05.825237Z",
          "shell.execute_reply.started": "2025-10-17T19:31:03.449222Z",
          "shell.execute_reply": "2025-10-17T19:31:05.824607Z"
        },
        "id": "EDUBnS1-_EXB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Instantiate SiHDNet model\n",
        "model_sihdnet = build_sihdnet_model(input_size=(256, 256, 6))\n",
        "\n",
        "# Compile the model\n",
        "model_sihdnet.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Show model summary\n",
        "model_sihdnet.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:31:13.796394Z",
          "iopub.execute_input": "2025-10-17T19:31:13.796878Z",
          "iopub.status.idle": "2025-10-17T19:31:14.061572Z",
          "shell.execute_reply.started": "2025-10-17T19:31:13.796854Z",
          "shell.execute_reply": "2025-10-17T19:31:14.060793Z"
        },
        "id": "zDx3wgkm_EXB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Instantiate GLAI-Net model\n",
        "model_glainet = build_glainet_model(input_size=(256, 256, 6))\n",
        "\n",
        "# Compile the model\n",
        "model_glainet.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Show model summary\n",
        "model_glainet.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:31:24.726504Z",
          "iopub.execute_input": "2025-10-17T19:31:24.727377Z",
          "iopub.status.idle": "2025-10-17T19:31:24.987898Z",
          "shell.execute_reply.started": "2025-10-17T19:31:24.727352Z",
          "shell.execute_reply": "2025-10-17T19:31:24.987292Z"
        },
        "id": "RoFzn3-f_EXB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Instantiate MTFSR model\n",
        "model_mtfsr = build_mtfsr_model(input_size=(256, 256, 6))\n",
        "\n",
        "# Compile the model\n",
        "model_mtfsr.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Show model summary\n",
        "model_mtfsr.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:31:38.120937Z",
          "iopub.execute_input": "2025-10-17T19:31:38.121443Z",
          "iopub.status.idle": "2025-10-17T19:31:38.38642Z",
          "shell.execute_reply.started": "2025-10-17T19:31:38.121422Z",
          "shell.execute_reply": "2025-10-17T19:31:38.385843Z"
        },
        "id": "-YmYZKJ2_EXC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Instantiate SifaNet model\n",
        "model_sifanet = build_sifanet_model(input_size=(256, 256, 6))\n",
        "\n",
        "# Compile the model\n",
        "model_sifanet.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Show model summary\n",
        "model_sifanet.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:33:00.829033Z",
          "iopub.execute_input": "2025-10-17T19:33:00.82934Z",
          "iopub.status.idle": "2025-10-17T19:33:01.098381Z",
          "shell.execute_reply.started": "2025-10-17T19:33:00.829321Z",
          "shell.execute_reply": "2025-10-17T19:33:01.097597Z"
        },
        "id": "BZECyQpE_EXC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Paths to LEVIR-CD+ dataset\n",
        "image1_train_dir = \"/kaggle/input/levir-cd/LEVIR CD/train/A\"\n",
        "image2_train_dir =  \"/kaggle/input/levir-cd/LEVIR CD/train/B\"\n",
        "mask_train_dir = \"/kaggle/input/levir-cd/LEVIR CD/train/label\"\n",
        "\n",
        "image1_val_dir = \"/kaggle/input/levir-cd/LEVIR CD/val/A\"\n",
        "image2_val_dir = \"/kaggle/input/levir-cd/LEVIR CD/val/B\"\n",
        "mask_val_dir   = \"/kaggle/input/levir-cd/LEVIR CD/val/label\"\n",
        "\n",
        "image1_test_dir =  \"/kaggle/input/levir-cd/LEVIR CD/test/A\"\n",
        "image2_test_dir =  \"/kaggle/input/levir-cd/LEVIR CD/test/B\"\n",
        "mask_test_dir = \"/kaggle/input/levir-cd/LEVIR CD/test/label\"\n",
        "\n",
        "input_shape = (256, 256)  # Resize dimensions\n",
        "\n",
        "def load_images(image1_dir, image2_dir, mask_dir):\n",
        "    image1_files = sorted(os.listdir(image1_dir))\n",
        "    image2_files = sorted(os.listdir(image2_dir))\n",
        "    mask_files = sorted(os.listdir(mask_dir))\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for img1, img2, mask in zip(image1_files, image2_files, mask_files):\n",
        "\n",
        "        img1_path = os.path.join(image1_dir, img1)\n",
        "        img2_path = os.path.join(image2_dir, img2)\n",
        "        mask_path = os.path.join(mask_dir, mask)\n",
        "\n",
        "        img1 = cv2.imread(img1_path)\n",
        "        img2 = cv2.imread(img2_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Resize images and mask\n",
        "        img1 = cv2.resize(img1, input_shape)\n",
        "        img2 = cv2.resize(img2, input_shape)\n",
        "        mask = cv2.resize(mask, input_shape)\n",
        "\n",
        "        # Normalize images and mask\n",
        "        img1 = img1 / 255.0\n",
        "        img2 = img2 / 255.0\n",
        "        mask = mask / 255.0\n",
        "\n",
        "        # Stack images along the channel axis\n",
        "        stacked_image = np.concatenate([img1, img2], axis=-1)  # Shape: (256, 256, 6)\n",
        "\n",
        "        X.append(stacked_image)\n",
        "        y.append(mask)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load datasets\n",
        "X_train, y_train = load_images(image1_train_dir, image2_train_dir, mask_train_dir)\n",
        "X_val, y_val     = load_images(image1_val_dir, image2_val_dir, mask_val_dir)\n",
        "X_test, y_test   = load_images(image1_test_dir, image2_test_dir, mask_test_dir)\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Validation set size:\", X_val.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:42:34.015148Z",
          "iopub.execute_input": "2025-10-17T19:42:34.015494Z",
          "iopub.status.idle": "2025-10-17T19:43:52.159153Z",
          "shell.execute_reply.started": "2025-10-17T19:42:34.015472Z",
          "shell.execute_reply": "2025-10-17T19:43:52.158292Z"
        },
        "id": "zOF-tcdy_EXC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "callbacks_unet = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(\"best_change_detection_unet_model.keras\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:44:52.162255Z",
          "iopub.execute_input": "2025-10-17T19:44:52.162838Z",
          "iopub.status.idle": "2025-10-17T19:44:52.166942Z",
          "shell.execute_reply.started": "2025-10-17T19:44:52.162816Z",
          "shell.execute_reply": "2025-10-17T19:44:52.166132Z"
        },
        "id": "OQcIud7e_EXC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks_unet_with_resnet = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(\"best_change_detection_unet_resnet_model.keras\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
        "]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:44:55.288265Z",
          "iopub.execute_input": "2025-10-17T19:44:55.288558Z",
          "iopub.status.idle": "2025-10-17T19:44:55.29313Z",
          "shell.execute_reply.started": "2025-10-17T19:44:55.288538Z",
          "shell.execute_reply": "2025-10-17T19:44:55.292373Z"
        },
        "id": "VVQ5P5ti_EXD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Callbacks for training\n",
        "callbacks_sihdnet = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(\"best_change_detection_sihdnet_model.keras\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:44:59.017683Z",
          "iopub.execute_input": "2025-10-17T19:44:59.017942Z",
          "iopub.status.idle": "2025-10-17T19:44:59.022946Z",
          "shell.execute_reply.started": "2025-10-17T19:44:59.017925Z",
          "shell.execute_reply": "2025-10-17T19:44:59.022014Z"
        },
        "id": "XAWCwe2W_EXD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===============================\n",
        "# Callbacks for training\n",
        "callbacks_glainet = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(\"best_change_detection_glainet_model.keras\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
        "]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:45:01.563805Z",
          "iopub.execute_input": "2025-10-17T19:45:01.564077Z",
          "iopub.status.idle": "2025-10-17T19:45:01.56916Z",
          "shell.execute_reply.started": "2025-10-17T19:45:01.56406Z",
          "shell.execute_reply": "2025-10-17T19:45:01.568273Z"
        },
        "id": "TBlzZAyV_EXE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Callbacks for training\n",
        "callbacks_mtfsr = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(\"best_change_detection_mtfsr_model.keras\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:45:06.230459Z",
          "iopub.execute_input": "2025-10-17T19:45:06.230742Z",
          "iopub.status.idle": "2025-10-17T19:45:06.235417Z",
          "shell.execute_reply.started": "2025-10-17T19:45:06.230723Z",
          "shell.execute_reply": "2025-10-17T19:45:06.234582Z"
        },
        "id": "hqzO2Xix_EXE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Callbacks for training\n",
        "callbacks_sifanet = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(\"best_change_detection_sihdnet_model.keras\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:45:08.888022Z",
          "iopub.execute_input": "2025-10-17T19:45:08.888867Z",
          "iopub.status.idle": "2025-10-17T19:45:08.893381Z",
          "shell.execute_reply.started": "2025-10-17T19:45:08.888842Z",
          "shell.execute_reply": "2025-10-17T19:45:08.892147Z"
        },
        "id": "PVGe-quz_EXE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "history_unet = model_unet.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=8,\n",
        "    epochs=25,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks_unet\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:45:11.779712Z",
          "iopub.execute_input": "2025-10-17T19:45:11.780318Z",
          "iopub.status.idle": "2025-10-17T19:53:02.206901Z",
          "shell.execute_reply.started": "2025-10-17T19:45:11.780291Z",
          "shell.execute_reply": "2025-10-17T19:53:02.205977Z"
        },
        "id": "EUnFrc76_EXE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history_unet_with_resnet = model_unet_with_resnet.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=8,\n",
        "    epochs=25,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks_unet_with_resnet\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:53:19.226749Z",
          "iopub.execute_input": "2025-10-17T19:53:19.227264Z",
          "iopub.status.idle": "2025-10-17T19:58:01.112603Z",
          "shell.execute_reply.started": "2025-10-17T19:53:19.227233Z",
          "shell.execute_reply": "2025-10-17T19:58:01.111897Z"
        },
        "id": "cQOP4uTq_EXE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Training the model\n",
        "history_sihdnet = model_sihdnet.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=8,\n",
        "    epochs=25,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks_sihdnet\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T19:58:41.419922Z",
          "iopub.execute_input": "2025-10-17T19:58:41.420683Z",
          "iopub.status.idle": "2025-10-17T20:05:53.692779Z",
          "shell.execute_reply.started": "2025-10-17T19:58:41.420654Z",
          "shell.execute_reply": "2025-10-17T20:05:53.692Z"
        },
        "id": "s8RN8Gs3_EXF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Training the model\n",
        "history_glainet = model_glainet.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=8,\n",
        "    epochs=25,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks_glainet\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:06:10.942719Z",
          "iopub.execute_input": "2025-10-17T20:06:10.943377Z",
          "iopub.status.idle": "2025-10-17T20:13:20.988517Z",
          "shell.execute_reply.started": "2025-10-17T20:06:10.943351Z",
          "shell.execute_reply": "2025-10-17T20:13:20.987889Z"
        },
        "id": "kiG0SCwc_EXF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Training the model\n",
        "history_mtfsr = model_mtfsr.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=8,\n",
        "    epochs=25,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks_mtfsr\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:13:40.692719Z",
          "iopub.execute_input": "2025-10-17T20:13:40.69347Z",
          "iopub.status.idle": "2025-10-17T20:20:47.558052Z",
          "shell.execute_reply.started": "2025-10-17T20:13:40.693445Z",
          "shell.execute_reply": "2025-10-17T20:20:47.557133Z"
        },
        "id": "k3mc-nKo_EXF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Training the model\n",
        "history_sifanet = model_sifanet.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=8,\n",
        "    epochs=25,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks_sifanet\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:21:41.818333Z",
          "iopub.execute_input": "2025-10-17T20:21:41.818946Z",
          "iopub.status.idle": "2025-10-17T20:28:52.78949Z",
          "shell.execute_reply.started": "2025-10-17T20:21:41.818923Z",
          "shell.execute_reply": "2025-10-17T20:28:52.788748Z"
        },
        "id": "xVrp1R3J_EXF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['U-Net model', 'U-Net with RES-Net model','sihdnet model','glainet model','mtfsr model','sihdnet model']\n",
        "history = [history_unet, history_unet_with_resnet ,history_sihdnet, history_glainet, history_mtfsr,history_sihdnet]\n",
        "for i in range(6):\n",
        "    for metric in ['loss', 'accuracy']:\n",
        "        plt.plot(history[i].history[metric], label='Training Loss')\n",
        "        plt.plot(history[i].history['val_' + metric], label='Validation Loss')\n",
        "        plt.title(models[i] + ' ' + metric)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel(metric)\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:28:57.601858Z",
          "iopub.execute_input": "2025-10-17T20:28:57.602636Z",
          "iopub.status.idle": "2025-10-17T20:28:59.853591Z",
          "shell.execute_reply.started": "2025-10-17T20:28:57.602612Z",
          "shell.execute_reply": "2025-10-17T20:28:59.852719Z"
        },
        "id": "O8k7TvJQ_EXF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model_unet_with_resnet.evaluate(X_test, y_test, batch_size=8, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predict on test set\n",
        "predictions_unet_with_resnet = model_unet_with_resnet.predict(X_test, batch_size=8, verbose=1)\n",
        "#predicted_masks = (predictions > 0.5).astype(int)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:29:12.658179Z",
          "iopub.execute_input": "2025-10-17T20:29:12.658805Z",
          "iopub.status.idle": "2025-10-17T20:29:25.917755Z",
          "shell.execute_reply.started": "2025-10-17T20:29:12.658781Z",
          "shell.execute_reply": "2025-10-17T20:29:25.917065Z"
        },
        "id": "j6b5EiAx_EXF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model_unet.evaluate(X_test, y_test, batch_size=8, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predict on test set\n",
        "predictions_unet = model_unet.predict(X_test, batch_size=8, verbose=1)\n",
        "#predicted_masks = (predictions > 0.5).astype(int)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:29:35.844777Z",
          "iopub.execute_input": "2025-10-17T20:29:35.845518Z",
          "iopub.status.idle": "2025-10-17T20:29:40.983098Z",
          "shell.execute_reply.started": "2025-10-17T20:29:35.845491Z",
          "shell.execute_reply": "2025-10-17T20:29:40.982401Z"
        },
        "id": "5clGHgp7_EXF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model_sihdnet.evaluate(X_test, y_test, batch_size=8, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predict on test set\n",
        "predictions_unet_sihdnet = model_sihdnet.predict(X_test, batch_size=8, verbose=1)\n",
        "#predicted_masks = (predictions > 0.5).astype(int)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:29:49.159176Z",
          "iopub.execute_input": "2025-10-17T20:29:49.159778Z",
          "iopub.status.idle": "2025-10-17T20:29:54.18294Z",
          "shell.execute_reply.started": "2025-10-17T20:29:49.159752Z",
          "shell.execute_reply": "2025-10-17T20:29:54.181956Z"
        },
        "id": "AGLQUHHk_EXF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model_glainet.evaluate(X_test, y_test, batch_size=8, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predict on test set\n",
        "predictions_unet_glainet = model_glainet.predict(X_test, batch_size=8, verbose=1)\n",
        "#predicted_masks = (predictions > 0.5).astype(int)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:30:01.449192Z",
          "iopub.execute_input": "2025-10-17T20:30:01.449883Z",
          "iopub.status.idle": "2025-10-17T20:30:06.482999Z",
          "shell.execute_reply.started": "2025-10-17T20:30:01.449858Z",
          "shell.execute_reply": "2025-10-17T20:30:06.482005Z"
        },
        "id": "2QOmG2xq_EXF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model_mtfsr.evaluate(X_test, y_test, batch_size=8, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predict on test set\n",
        "predictions_unet_mtfsr = model_mtfsr.predict(X_test, batch_size=8, verbose=1)\n",
        "#predicted_masks = (predictions > 0.5).astype(int)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:30:11.012835Z",
          "iopub.execute_input": "2025-10-17T20:30:11.013364Z",
          "iopub.status.idle": "2025-10-17T20:30:16.005779Z",
          "shell.execute_reply.started": "2025-10-17T20:30:11.013327Z",
          "shell.execute_reply": "2025-10-17T20:30:16.004799Z"
        },
        "id": "NSRz9X-T_EXG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model_sifanet.evaluate(X_test, y_test, batch_size=8, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predict on test set\n",
        "predictions_unet_sifanet = model_sifanet.predict(X_test, batch_size=8, verbose=1)\n",
        "#predicted_masks = (predictions > 0.5).astype(int)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:30:20.013971Z",
          "iopub.execute_input": "2025-10-17T20:30:20.014774Z",
          "iopub.status.idle": "2025-10-17T20:30:24.986274Z",
          "shell.execute_reply.started": "2025-10-17T20:30:20.014746Z",
          "shell.execute_reply": "2025-10-17T20:30:24.985382Z"
        },
        "id": "l1E_1IHP_EXG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def overlay_mask(image, mask, color=(255, 0, 0), alpha=0.5, max_val = 0.2):\n",
        "\n",
        "    mask_colored = np.zeros_like(image, dtype=np.uint8)\n",
        "    mask_colored[mask > max_val] = color\n",
        "\n",
        "    overlayed = cv2.addWeighted(image, 1, mask_colored, alpha, 0)\n",
        "\n",
        "    return overlayed\n",
        "\n",
        "\n",
        "predictions = [predictions_unet_with_resnet, predictions_unet,predictions_unet_sihdnet,predictions_unet_glainet,predictions_unet_mtfsr,predictions_unet_sifanet]\n",
        "models = ['U-Net model', 'U-Net with RES-Net model','sihdnet model','glainet model','mtfsr model','sihdnet model']\n",
        "\n",
        "for k in range(6):\n",
        "    print('-----------------------------'+ models[k] +'----------------------------------------')\n",
        "\n",
        "    # Visualize results\n",
        "    for i in range(6):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 4, 1)\n",
        "        plt.imshow(X_test[i, :, :, :3])\n",
        "        plt.title(\"Input Image 1\")\n",
        "        plt.subplot(1, 4, 2)\n",
        "        plt.imshow(X_test[i, :, :, 3:])\n",
        "        plt.title(\"Input Image 2\")\n",
        "        plt.subplot(1, 4, 3)\n",
        "        plt.imshow(y_test[i].squeeze(), cmap='gray')\n",
        "        plt.title(\"Ground Truth Mask\")\n",
        "        plt.subplot(1, 4, 4)\n",
        "        plt.imshow(predictions[k][i].squeeze(), cmap='gray')\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        plt.show()\n",
        "        print(f\"Predictions Min: {predictions[k][i].min()}, Max: {predictions[k][i].max()}\")\n",
        "\n",
        "\n",
        "        # Overlay mask on image\n",
        "        overlayed_image_1 = overlay_mask((X_test[i, :, :, :3] * 255).astype(np.uint8), predictions[k][i].squeeze(), color=(255, 0, 0), alpha=0.5)\n",
        "        overlayed_image_2 = overlay_mask((X_test[i, :, :, 3:] * 255).astype(np.uint8), predictions[k][i].squeeze(), color=(255, 0, 0), alpha=0.5)\n",
        "\n",
        "        # Display results\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(overlayed_image_1)\n",
        "        plt.title(\"Overlayed Image - 1\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(overlayed_image_2)\n",
        "        plt.title(\"Overlayed Image - 2\")\n",
        "\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:30:28.954271Z",
          "iopub.execute_input": "2025-10-17T20:30:28.954604Z",
          "iopub.status.idle": "2025-10-17T20:31:10.924809Z",
          "shell.execute_reply.started": "2025-10-17T20:30:28.954586Z",
          "shell.execute_reply": "2025-10-17T20:31:10.923788Z"
        },
        "id": "fAawnw___EXG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to save the best model\n",
        "best_model_path = '/kaggle/working/sihdnet_best_model.h5'\n",
        "\n",
        "# Check if model already exists\n",
        "if os.path.exists(best_model_path):\n",
        "    print(\"Best model is already saved\")\n",
        "else:\n",
        "    model_sihdnet.save(best_model_path)\n",
        "    print(\"Best model (SiHDNet) saved successfully\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:31:11.39462Z",
          "iopub.execute_input": "2025-10-17T20:31:11.395307Z",
          "iopub.status.idle": "2025-10-17T20:31:11.409364Z",
          "shell.execute_reply.started": "2025-10-17T20:31:11.39528Z",
          "shell.execute_reply": "2025-10-17T20:31:11.408553Z"
        },
        "id": "vaUyysNP_EXG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_weights_path = '/kaggle/working/sihdnet_best_model_weights.weights.h5'\n",
        "import os\n",
        "\n",
        "# Path to save the best model weights\n",
        "best_weights_path = '/kaggle/working/sihdnet_best_model_weights.weights.h5'\n",
        "\n",
        "# Check if weights file already exists\n",
        "if os.path.exists(best_weights_path):\n",
        "    print(\"Best model weights are already saved\")\n",
        "else:\n",
        "    # Save only weights of the best model (SiHDNet)\n",
        "    model_sihdnet.save_weights(best_weights_path)\n",
        "    print(\"Best model weights (SiHDNet) saved successfully\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:31:30.312758Z",
          "iopub.execute_input": "2025-10-17T20:31:30.313054Z",
          "iopub.status.idle": "2025-10-17T20:31:30.318896Z",
          "shell.execute_reply.started": "2025-10-17T20:31:30.313032Z",
          "shell.execute_reply": "2025-10-17T20:31:30.318133Z"
        },
        "id": "qqK9zxyh_EXH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models = ['U-Net model', 'U-Net with RES-Net model','SIHDNet model','GLAInet model','MTFSR model','SIHDNet model']\n",
        "history_list = [history_unet, history_unet_with_resnet, history_sihdnet, history_glainet, history_mtfsr, history_sihdnet]\n",
        "metrics = ['accuracy', 'f1_score', 'iou']\n",
        "\n",
        "# =========================\n",
        "# 1. Bar Plot – Last Epoch Comparison\n",
        "# =========================\n",
        "bar_data = {metric: [] for metric in metrics}\n",
        "\n",
        "for i, hist in enumerate(history_list):\n",
        "    for metric in metrics:\n",
        "        if metric in hist.history:\n",
        "            bar_data[metric].append(hist.history[metric][-1])\n",
        "        else:\n",
        "            bar_data[metric].append(0)\n",
        "\n",
        "df_bar = pd.DataFrame(bar_data, index=models)\n",
        "plt.figure(figsize=(20,12))  # বড় figure\n",
        "df_bar.plot(kind='bar', figsize=(20,12))\n",
        "plt.title(\"Model-wise Metrics Comparison (Last Epoch)\", fontsize=20)\n",
        "plt.ylabel(\"Metric Value\", fontsize=16)\n",
        "plt.ylim(0,1)\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:54:53.78261Z",
          "iopub.execute_input": "2025-10-17T20:54:53.782901Z",
          "iopub.status.idle": "2025-10-17T20:54:54.09645Z",
          "shell.execute_reply.started": "2025-10-17T20:54:53.782882Z",
          "shell.execute_reply": "2025-10-17T20:54:54.095545Z"
        },
        "id": "SBzW6lQR_EXH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. Box Plot – Metric Distribution per Model\n",
        "# =========================\n",
        "box_data = []\n",
        "\n",
        "for i, hist in enumerate(history_list):\n",
        "    for metric in metrics:\n",
        "        if metric in hist.history:\n",
        "            for value in hist.history[metric]:\n",
        "                box_data.append({'Model': models[i], 'Metric': metric, 'Value': value})\n",
        "\n",
        "df_box = pd.DataFrame(box_data)\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "sns.boxplot(x='Metric', y='Value', hue='Model', data=df_box)\n",
        "plt.title(\"Metric Distribution per Model (Box Plot)\", fontsize=20)\n",
        "plt.ylim(0,1)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:55:43.050745Z",
          "iopub.execute_input": "2025-10-17T20:55:43.051062Z",
          "iopub.status.idle": "2025-10-17T20:55:43.362697Z",
          "shell.execute_reply.started": "2025-10-17T20:55:43.051039Z",
          "shell.execute_reply": "2025-10-17T20:55:43.361707Z"
        },
        "id": "D0G3BtF__EXH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. Violin Plot – Metric Distribution per Model (split=False)\n",
        "# =========================\n",
        "plt.figure(figsize=(20,12))\n",
        "sns.violinplot(x='Metric', y='Value', hue='Model', data=df_box, split=False)  # split=False important\n",
        "plt.title(\"Metric Distribution per Model (Violin Plot)\", fontsize=20)\n",
        "plt.ylim(0,1)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T20:56:52.432706Z",
          "iopub.execute_input": "2025-10-17T20:56:52.432961Z",
          "iopub.status.idle": "2025-10-17T20:56:52.785837Z",
          "shell.execute_reply.started": "2025-10-17T20:56:52.432944Z",
          "shell.execute_reply": "2025-10-17T20:56:52.785122Z"
        },
        "id": "KmXyY3yZ_EXI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "3Uf_Vnss_EXI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "aEzPaiCF_EXI"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}